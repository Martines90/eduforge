# Golden Master Tests - Prompt Regression Protection

## ğŸ“‹ What Are Golden Masters?

Golden masters are **reference snapshots** of the complete prompts (system message + user message) that our task generation system produces for specific curriculum topics.

They serve as **regression tests** that catch unintended changes to prompt generation logic.

## ğŸ¯ Purpose

The prompt generation system is complex, with many moving parts:
- 4 core universal modules (shared across all subjects)
- 4 subject-specific modules per subject
- Curriculum data injection from JSON files
- Variation-specific hint selection (randomly picked but deterministic)
- Country/grade/subject-specific configuration
- Template composition logic

**A small bug anywhere in this chain can silently break prompt quality.**

Golden master tests catch these bugs by comparing:
- **Expected**: The reference prompts saved in this directory
- **Actual**: The prompts generated by the current code

If they don't match â†’ **Test fails** â†’ You know something changed.

## ğŸ“ Directory Structure

```
golden-masters/
â””â”€â”€ mx/                          # Mexico curriculum
    â”œâ”€â”€ grade_3_6/               # Elementary (grades 3-6)
    â”‚   â”œâ”€â”€ biology/
    â”‚   â”‚   â”œâ”€â”€ system_message.md    # Full system prompt
    â”‚   â”‚   â””â”€â”€ user_message.json    # Curriculum data + hints
    â”‚   â”œâ”€â”€ chemistry/
    â”‚   â”œâ”€â”€ geography/
    â”‚   â”œâ”€â”€ history/
    â”‚   â”œâ”€â”€ informatics/
    â”‚   â”œâ”€â”€ literature/
    â”‚   â”œâ”€â”€ mathematics/
    â”‚   â””â”€â”€ physics/
    â”œâ”€â”€ grade_7_9/               # Middle school (grades 7-9)
    â”‚   â””â”€â”€ (same 8 subjects)
    â””â”€â”€ grade_10_12/             # High school (grades 10-12)
        â””â”€â”€ (same 8 subjects)
```

**Total: 24 combinations** (8 subjects Ã— 3 grade levels)

## ğŸ” What Gets Tested?

Each golden master combination tests:

### 1. **System Message** (`system_message.md`)
- âœ… Core module composition (universal principles, curriculum alignment, etc.)
- âœ… Subject-specific module composition (problem types, archetypes, etc.)
- âœ… Template structure and ordering
- âœ… Complete prompt content delivered to the AI

### 2. **User Message** (`user_message.json`)
- âœ… Curriculum topic data (name, description, example tasks)
- âœ… Task configuration (language, metric system)
- âœ… Task ID hints
- âœ… All variation-specific content

## ğŸš€ How to Use

### Running Golden Master Tests

```bash
# Run all tests (includes golden masters)
npm test

# Run ONLY golden master tests
npm run test:golden-masters
```

### When Tests Pass âœ…

Everything is working correctly! Your code generates the same prompts as the reference.

### When Tests Fail âŒ

**You have two options:**

#### Option 1: You Fixed a Bug / Made Intentional Changes

If the difference is **intentional** (you improved the prompts):

```bash
# Regenerate all 24 golden masters with current code
npm run golden-masters:update
```

This overwrites the reference files with new "correct" prompts.

Then commit the updated golden masters to git:
```bash
git add src/services/__tests__/golden-masters/
git commit -m "Update golden masters after [describe your change]"
```

#### Option 2: You Broke Something

If the difference is **unintentional** (a bug):

1. Look at the test failure output to see what changed
2. Fix the bug in your code
3. Re-run tests until they pass

## ğŸ”§ Generating Golden Masters from Scratch

If you need to regenerate all 24 reference files:

```bash
npm run golden-masters:generate
```

This:
1. Creates the directory structure
2. Generates prompts for all 24 combinations
3. Saves system_message.md and user_message.json for each
4. Uses **fixed randomness** for deterministic hint selection

## âš™ï¸ How It Works

### Deterministic Generation

To ensure golden masters are reproducible, the generator:

1. **Fixes `Math.random()`** to return a predetermined sequence:
   ```typescript
   const FIXED_RANDOM_SEQUENCE = [0.42, 0.17, 0.89, 0.33, ...];
   Math.random = () => FIXED_RANDOM_SEQUENCE[callCount++ % length];
   ```

2. **Uses fixed parameters**:
   - Variation index: Always `1`
   - Location: Always `"North America"`
   - Difficulty: Always `"medium"`
   - Target group: Always `"mixed"`

3. **Real curriculum data**: Uses actual JSON files from the curriculum system

### Test Methodology

The test file (`golden-master.test.ts`):
1. Generates prompts with the same fixed randomness
2. Loads the saved golden master files
3. Compares them character-by-character
4. Fails if ANY difference is found

## ğŸ“Š Coverage

Golden masters test **24 critical prompt generation scenarios**:

| Subject      | Grade 3-6 | Grade 7-9 | Grade 10-12 |
|--------------|-----------|-----------|-------------|
| Biology      | âœ…        | âœ…        | âœ…          |
| Chemistry    | âœ…        | âœ…        | âœ…          |
| Geography    | âœ…        | âœ…        | âœ…          |
| History      | âœ…        | âœ…        | âœ…          |
| Informatics  | âœ…        | âœ…        | âœ…          |
| Literature   | âœ…        | âœ…        | âœ…          |
| Mathematics  | âœ…        | âœ…        | âœ…          |
| Physics      | âœ…        | âœ…        | âœ…          |

## ğŸ¯ Example: What a Test Catches

**Scenario**: You refactor template-composer.ts and accidentally change module loading order.

**Without Golden Masters**:
- âŒ No test fails
- âŒ Prompts are silently different
- âŒ AI behavior changes in production
- âŒ Users notice quality degradation

**With Golden Masters**:
- âœ… Test fails immediately
- âœ… You see exactly what changed in the diff
- âœ… You fix the module order
- âœ… Tests pass, quality maintained

## ğŸ“ Best Practices

### When to Update Golden Masters

âœ… **DO update** when:
- You intentionally improve prompt quality
- You add new module content
- You refactor but want the same output
- You fix a bug that changes output (for the better)

âŒ **DON'T update** when:
- Tests fail and you don't know why
- You're trying to "make tests pass" without understanding the change
- Someone else changed the code and you don't understand it

### Reviewing Changes

When updating golden masters, **always review the diff**:

```bash
git diff src/services/__tests__/golden-masters/
```

**Ask yourself**:
- Is this change intentional?
- Does it improve prompt quality?
- Does it break anything?

If you can't confidently answer "yes, yes, no" â†’ **Don't commit.**

## ğŸ”’ Git Workflow

Golden masters should be **version controlled**:

```bash
# After updating golden masters
git add src/services/__tests__/golden-masters/
git commit -m "docs: update golden masters after [your change]"

# Include rationale in commit message
git commit -m "feat: add new chemistry archetypes

Updated golden masters to include 3 new chemistry scenario
archetypes focusing on industrial applications."
```

## ğŸ› Debugging Failed Tests

If a golden master test fails:

### 1. See What Changed
```bash
npm run test:golden-masters -- --verbose
```

This shows the exact diff between expected and actual.

### 2. Identify the Root Cause
Look for patterns:
- Did ALL subjects change? â†’ Core module issue
- Did ONE subject change? â†’ Subject-specific module issue
- Did curriculum data change? â†’ JSON file issue
- Did hints change? â†’ Random sequence issue

### 3. Fix or Accept
- **Fix**: If it's a bug, fix the code
- **Accept**: If it's intentional, update golden masters

## ğŸ“ˆ Benefits

1. **Regression Protection**: Catches unintended changes immediately
2. **Refactoring Confidence**: Change code structure without fear
3. **Documentation**: Golden masters show exactly what the system produces
4. **Debugging**: Easy to compare "before" vs "after" when things break
5. **Quality Assurance**: Ensures prompts remain consistent across deployments

## âš ï¸ Limitations

Golden masters test **prompt generation**, not:
- âŒ AI model responses
- âŒ Task quality (that's subjective)
- âŒ User experience
- âŒ Performance/speed

They ensure your **code** produces consistent **output**, not that the output is "good."

## ğŸ¤ Contributing

When adding new subjects or grade levels:

1. Add curriculum paths to `generate-golden-masters.ts`
2. Run `npm run golden-masters:generate`
3. Review generated prompts for quality
4. Add the new golden masters to git
5. Update this README if needed

## ğŸ“š Related Files

- `generate-golden-masters.ts` - Script to generate reference files
- `golden-master.test.ts` - Test that compares current vs. reference
- `template-composer.ts` - Core module composition logic
- `system-prompt-builder.helper.ts` - System prompt construction

---

**Last updated**: 2026-01-17
**Generated combinations**: 24 (8 subjects Ã— 3 grades)
**Test coverage**: 100% of Mexico curriculum subject-grade matrix
